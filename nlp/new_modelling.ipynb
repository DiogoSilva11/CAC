{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from xgboost import XGBClassifier\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load review sentiment data\n",
    "\n",
    "review_df = pd.read_csv('data/review_sentiment.csv')\n",
    "\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = {\n",
    "    0: 'bag_of_words',\n",
    "    1: 'one_hot',\n",
    "    2: 'n_grams',\n",
    "    3: 'tf_idf',\n",
    "    4: 'word2vec',\n",
    "    5: 'combined_bow_negation',\n",
    "    6: 'lsa_topic_matrix',\n",
    "    7: 'lda_topic_matrix'\n",
    "}\n",
    "# Load all feature sets\n",
    "features = {}\n",
    "for key, feature_name in feature_set.items():\n",
    "    if key == 4 or key == 6 or key == 7:\n",
    "        features[key] = np.load('features/' + feature_name + '.npy')\n",
    "    else:\n",
    "        features[key] = sparse.load_npz('features/' + feature_name + '.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target labels\n",
    "\n",
    "y = review_df['sentiment'].to_numpy()\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers\n",
    "\n",
    "classifiers = {\n",
    "    'gaussian_nb': GaussianNB(),\n",
    "    'decision_tree': DecisionTreeClassifier(),\n",
    "    'random_forest': RandomForestClassifier(),\n",
    "    'svm': SVC(),\n",
    "    'perceptron': Perceptron(tol=1e-3, random_state=0),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'gaussian_nb': {},\n",
    "    'decision_tree': {\n",
    "        'max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10]\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.1, 1.0],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'perceptron': {\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'penalty': [None, 'l2']\n",
    "    },\n",
    "    'xgb': {\n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'n_estimators': [100, 200]\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'C': [0.1, 1.0],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec features for grid search\n",
    "word2vec_features = features[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets using word2vec features\n",
    "X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(word2vec_features, y, test_size=0.20, random_state=42)\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_w2v, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb algorithm expects [0 1 2], not [-1 0 1]\n",
    "\n",
    "# Convert numpy arrays to pandas Series\n",
    "y_train_series = pd.Series(y_train_resampled)\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Remap labels: -1 -> 0, 0 -> 1, 1 -> 2\n",
    "y_train_mapped = y_train_series.map({-1: 0, 0: 1, 1: 2})\n",
    "y_test_mapped = y_test_series.map({-1: 0, 0: 1, 1: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = {}\n",
    "grid_results = []\n",
    "\n",
    "# Apply grid search to each classifier using word2vec features\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Grid search for {clf_name}\")\n",
    "    param_grid = param_grids[clf_name]\n",
    "    if clf_name == 'xgb':\n",
    "        grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=5)\n",
    "        grid_search.fit(X_train_resampled, y_train_mapped)\n",
    "    else:\n",
    "        grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=5)\n",
    "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "    best_estimators[clf_name] = grid_search.best_estimator_\n",
    "    grid_results.append({\n",
    "        'classifier': clf_name,\n",
    "        'best_parameters': grid_search.best_params_,\n",
    "        'best_accuracy': grid_search.best_score_,\n",
    "    })\n",
    "    print(f\"Best parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best accuracy for {clf_name}: {grid_search.best_score_}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "\n",
    "grid_results_df = pd.DataFrame(grid_results)\n",
    "grid_results_df.to_csv('grid_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_classifiers = {\n",
    "#     'multinomial_nb': MultinomialNB(),\n",
    "#     'gaussian_nb': GaussianNB(),\n",
    "#     'xgb': XGBClassifier(learning_rate=0.1, max_depth=5, n_estimators=200),\n",
    "#     'decision_tree': DecisionTreeClassifier(max_depth=10),\n",
    "#     'random_forest': RandomForestClassifier(max_depth=10, n_estimators=200),\n",
    "#     'svm': SVC(C=1.0, kernel='rbf'),\n",
    "#     'perceptron': Perceptron(tol=1e-3, random_state=0, alpha=0.0001, penalty=None),\n",
    "#     'logistic_regression': LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "# }\n",
    "# adding multinomial_nb\n",
    "best_estimators['multinomial_nb'] = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through each feature set\n",
    "for feature_key, feature_name in feature_set.items():\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features[feature_key], y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Oversample to balance the classes\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # change -1 to 2 because of xbg\n",
    "    y_train_resampled_series = pd.Series(y_train_resampled)\n",
    "    y_test_series = pd.Series(y_test)\n",
    "    y_train_resampled_mapped = y_train_resampled_series.map({-1: 0, 0: 1, 1: 2})\n",
    "    y_test_mapped = y_test_series.map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "\n",
    "    print(f\"Using {feature_name} features:\")\n",
    "    \n",
    "    # Loop through each classifier\n",
    "    for clf_name, clf in best_estimators.items():\n",
    "        print(f\"Training {clf_name} with {feature_name} features...\")   \n",
    "        \n",
    "        if clf_name == 'multinomial_nb' and feature_key in [4, 6, 7]:\n",
    "            print(f\"Skipping {clf_name} with {feature_name} features due to negative values or unsuitable feature type.\")\n",
    "            continue\n",
    "        # Convert sparse to dense if necessary\n",
    "        if (feature_key != 4 and feature_key != 6 and feature_key != 7) and clf_name in ['gaussian_nb', 'multinomial_nb', 'perceptron']:\n",
    "            X_train_dense = X_train_resampled.toarray()\n",
    "            X_test_dense = X_test.toarray()\n",
    "            clf.fit(X_train_dense, y_train_resampled)\n",
    "            y_pred = clf.predict(X_test_dense)\n",
    "        else:\n",
    "            if clf_name == 'xgb':\n",
    "                clf.fit(X_train_resampled, y_train_resampled_mapped)\n",
    "            else:\n",
    "                clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        if clf_name == 'xgb':\n",
    "            acc = accuracy_score(y_test_mapped, y_pred)\n",
    "            precision = precision_score(y_test_mapped, y_pred, average='macro')\n",
    "            recall = recall_score(y_test_mapped, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test_mapped, y_pred, average='macro')\n",
    "        else:\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        print(f\"Accuracy of {clf_name} with {feature_name} features: {acc}\")\n",
    "        print(f\"Precision of {clf_name} with {feature_name} features: {precision}\")\n",
    "        print(f\"Recall of {clf_name} with {feature_name} features: {recall}\")\n",
    "        print(f\"F1 Score of {clf_name} with {feature_name} features: {f1}\")\n",
    "            \n",
    "    # Append the results to the list\n",
    "        results.append({\n",
    "            'feature_set': feature_name,\n",
    "            'classifier': clf_name,\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        })\n",
    "        print(\"--------------------------------------\")\n",
    "\n",
    "    print(\"-------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('classification_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
